+-----------------+--------+
|    Parameter    | Value  |
+=================+========+
| Batch size      | 32     |
+-----------------+--------+
| Dataset         | MUTAG  |
+-----------------+--------+
| Epochs          | 10000  |
+-----------------+--------+
| Exp name        | MUTAG  |
+-----------------+--------+
| Gpu index       | 0      |
+-----------------+--------+
| Improved        | False  |
+-----------------+--------+
| Lr              | 0.0005 |
+-----------------+--------+
| Patience        | 40     |
+-----------------+--------+
| Pooling ratio   | 0.8    |
+-----------------+--------+
| Seed            | 1227   |
+-----------------+--------+
| Test batch size | 1      |
+-----------------+--------+
| Weight decay    | 0.0001 |
+-----------------+--------+
Using GPU: 0
GraphUNets(
  (conv1): GCNConv(7, 32)
  (conv2): GCNConv(32, 64)
  (conv3): GCNConv(64, 128)
  (conv4): GCNConv(128, 256)
  (pool1): GPool(
    (p): Linear(in_features=32, out_features=1, bias=False)
  )
  (pool2): GPool(
    (p): Linear(in_features=64, out_features=1, bias=False)
  )
  (pool3): GPool(
    (p): Linear(in_features=128, out_features=1, bias=False)
  )
  (unpool): GUnpool()
  (conv5): GCNConv(384, 128)
  (conv6): GCNConv(192, 64)
  (conv7): GCNConv(96, 32)
  (ac): ELU(alpha=1.0)
  (l1): Linear(in_features=64, out_features=64, bias=False)
  (classifier): Linear(in_features=64, out_features=2, bias=True)
)
Model Parameter: 112898
Using Adam

Epoch #000, Train_Loss: [0.6925, 0.6820, 0.6750, 0.6798, 0.6585]
Val_Loss: 0.642000, Val_Acc: 0.722222
The current best model is saved in: ******** outputs/MUTAG/model.pth *********

Epoch #001, Train_Loss: [0.6413, 0.6663, 0.6225, 0.6621, 0.6080]
Val_Loss: 0.597224, Val_Acc: 0.722222
The current best model is saved in: ******** outputs/MUTAG/model.pth *********

Epoch #002, Train_Loss: [0.6450, 0.5661, 0.4809, 0.6539, 0.8264]
Val_Loss: 0.573448, Val_Acc: 0.722222
The current best model is saved in: ******** outputs/MUTAG/model.pth *********

Epoch #003, Train_Loss: [0.6673, 0.6608, 0.5625, 0.6422, 0.4553]
Val_Loss: 0.573563, Val_Acc: 0.722222

Epoch #004, Train_Loss: [0.5879, 0.5261, 0.6916, 0.6515, 0.5417]
Val_Loss: 0.573624, Val_Acc: 0.722222

Epoch #005, Train_Loss: [0.7546, 0.5450, 0.5713, 0.5729, 0.5357]
Val_Loss: 0.568947, Val_Acc: 0.722222
The current best model is saved in: ******** outputs/MUTAG/model.pth *********

Epoch #006, Train_Loss: [0.5614, 0.5921, 0.6872, 0.5646, 0.5255]
Val_Loss: 0.578418, Val_Acc: 0.722222

Epoch #007, Train_Loss: [0.5711, 0.5482, 0.6125, 0.6588, 0.5122]
Val_Loss: 0.567887, Val_Acc: 0.722222
The current best model is saved in: ******** outputs/MUTAG/model.pth *********

Epoch #008, Train_Loss: [0.5503, 0.6054, 0.5049, 0.6086, 0.6372]
Val_Loss: 0.578870, Val_Acc: 0.722222

Epoch #009, Train_Loss: [0.5865, 0.6949, 0.6414, 0.4292, 0.5296]
Val_Loss: 0.571748, Val_Acc: 0.722222

Epoch #010, Train_Loss: [0.6116, 0.6408, 0.5745, 0.4671, 0.4910]
Val_Loss: 0.556883, Val_Acc: 0.722222
The current best model is saved in: ******** outputs/MUTAG/model.pth *********

Epoch #011, Train_Loss: [0.4919, 0.5440, 0.5782, 0.5288, 0.6612]
Val_Loss: 0.570853, Val_Acc: 0.722222

Epoch #012, Train_Loss: [0.5363, 0.5674, 0.5851, 0.5605, 0.5181]
Val_Loss: 0.575215, Val_Acc: 0.722222

Epoch #013, Train_Loss: [0.4930, 0.6773, 0.5133, 0.4966, 0.5687]
Val_Loss: 0.569924, Val_Acc: 0.722222

Epoch #014, Train_Loss: [0.5251, 0.5412, 0.6350, 0.3987, 0.5642]
Val_Loss: 0.576935, Val_Acc: 0.722222

Epoch #015, Train_Loss: [0.5841, 0.4789, 0.4504, 0.5255, 0.5373]
Val_Loss: 0.582740, Val_Acc: 0.722222

Epoch #016, Train_Loss: [0.5503, 0.4662, 0.5125, 0.5166, 0.4525]
Val_Loss: 0.580295, Val_Acc: 0.777778

Epoch #017, Train_Loss: [0.5208, 0.5528, 0.4397, 0.5691, 0.4552]
Val_Loss: 0.570966, Val_Acc: 0.777778

Epoch #018, Train_Loss: [0.4261, 0.6572, 0.6358, 0.4685, 0.4397]
Val_Loss: 0.584667, Val_Acc: 0.777778

Epoch #019, Train_Loss: [0.5357, 0.5576, 0.4214, 0.4497, 0.5437]
Val_Loss: 0.583829, Val_Acc: 0.777778

Epoch #020, Train_Loss: [0.4541, 0.5947, 0.4567, 0.4859, 0.7068]
Val_Loss: 0.547101, Val_Acc: 0.777778
The current best model is saved in: ******** outputs/MUTAG/model.pth *********

Epoch #021, Train_Loss: [0.3962, 0.5422, 0.5304, 0.4667, 0.6112]
Val_Loss: 0.597128, Val_Acc: 0.722222

Epoch #022, Train_Loss: [0.4375, 0.4721, 0.4948, 0.5185, 0.5352]
Val_Loss: 0.611260, Val_Acc: 0.777778

Epoch #023, Train_Loss: [0.6113, 0.2848, 0.6508, 0.4840, 0.5077]
Val_Loss: 0.601996, Val_Acc: 0.777778

Epoch #024, Train_Loss: [0.4471, 0.4667, 0.5304, 0.5235, 0.5979]
Val_Loss: 0.573047, Val_Acc: 0.777778

Epoch #025, Train_Loss: [0.5392, 0.6296, 0.5290, 0.4921, 0.3783]
Val_Loss: 0.588452, Val_Acc: 0.777778

Epoch #026, Train_Loss: [0.3878, 0.5529, 0.4949, 0.4935, 0.5828]
Val_Loss: 0.612799, Val_Acc: 0.777778

Epoch #027, Train_Loss: [0.4347, 0.5161, 0.5145, 0.5472, 0.5950]
Val_Loss: 0.535344, Val_Acc: 0.833333
The current best model is saved in: ******** outputs/MUTAG/model.pth *********

Epoch #028, Train_Loss: [0.5506, 0.4359, 0.6298, 0.4504, 0.5017]
Val_Loss: 0.543483, Val_Acc: 0.833333

Epoch #029, Train_Loss: [0.6143, 0.4610, 0.5271, 0.4482, 0.4002]
Val_Loss: 0.591349, Val_Acc: 0.777778

Epoch #030, Train_Loss: [0.4940, 0.4652, 0.4353, 0.6980, 0.3880]
Val_Loss: 0.557279, Val_Acc: 0.722222

Epoch #031, Train_Loss: [0.6146, 0.6277, 0.2893, 0.4668, 0.4317]
Val_Loss: 0.544783, Val_Acc: 0.833333

Epoch #032, Train_Loss: [0.4710, 0.5421, 0.4561, 0.5828, 0.4883]
Val_Loss: 0.540952, Val_Acc: 0.777778

Epoch #033, Train_Loss: [0.4784, 0.4235, 0.6197, 0.5274, 0.5770]
Val_Loss: 0.541901, Val_Acc: 0.777778

Epoch #034, Train_Loss: [0.4862, 0.6094, 0.4857, 0.5152, 0.4071]
Val_Loss: 0.533218, Val_Acc: 0.833333
The current best model is saved in: ******** outputs/MUTAG/model.pth *********

Epoch #035, Train_Loss: [0.4935, 0.5530, 0.4762, 0.5330, 0.3832]
Val_Loss: 0.542239, Val_Acc: 0.722222

Epoch #036, Train_Loss: [0.6092, 0.5122, 0.5921, 0.3100, 0.5186]
Val_Loss: 0.542114, Val_Acc: 0.777778

Epoch #037, Train_Loss: [0.4431, 0.5602, 0.4543, 0.4993, 0.4280]
Val_Loss: 0.538046, Val_Acc: 0.777778

Epoch #038, Train_Loss: [0.5331, 0.4393, 0.4681, 0.5728, 0.4412]
Val_Loss: 0.538764, Val_Acc: 0.777778

Epoch #039, Train_Loss: [0.4555, 0.5500, 0.5525, 0.5303, 0.3894]
Val_Loss: 0.538422, Val_Acc: 0.777778

Epoch #040, Train_Loss: [0.4732, 0.6733, 0.5129, 0.4437, 0.3582]
Val_Loss: 0.527001, Val_Acc: 0.777778
The current best model is saved in: ******** outputs/MUTAG/model.pth *********

Epoch #041, Train_Loss: [0.4836, 0.4599, 0.6371, 0.3762, 0.4735]
Val_Loss: 0.527231, Val_Acc: 0.777778

Epoch #042, Train_Loss: [0.4854, 0.5448, 0.4470, 0.4750, 0.4975]
Val_Loss: 0.523508, Val_Acc: 0.833333
The current best model is saved in: ******** outputs/MUTAG/model.pth *********

Epoch #043, Train_Loss: [0.5299, 0.5302, 0.4804, 0.4066, 0.4591]
Val_Loss: 0.531702, Val_Acc: 0.777778

Epoch #044, Train_Loss: [0.5005, 0.5286, 0.4109, 0.5592, 0.4124]
Val_Loss: 0.517892, Val_Acc: 0.833333
The current best model is saved in: ******** outputs/MUTAG/model.pth *********

Epoch #045, Train_Loss: [0.4468, 0.4104, 0.4854, 0.5937, 0.5204]
Val_Loss: 0.514129, Val_Acc: 0.777778
The current best model is saved in: ******** outputs/MUTAG/model.pth *********

Epoch #046, Train_Loss: [0.3714, 0.5037, 0.4958, 0.6026, 0.4520]
Val_Loss: 0.520958, Val_Acc: 0.833333

Epoch #047, Train_Loss: [0.5731, 0.3254, 0.5050, 0.4360, 0.5558]
Val_Loss: 0.532425, Val_Acc: 0.777778

Epoch #048, Train_Loss: [0.6329, 0.5639, 0.4504, 0.3538, 0.3906]
Val_Loss: 0.534254, Val_Acc: 0.777778

Epoch #049, Train_Loss: [0.5382, 0.3724, 0.4564, 0.4663, 0.5941]
Val_Loss: 0.536721, Val_Acc: 0.777778

Epoch #050, Train_Loss: [0.3110, 0.7073, 0.7228, 0.3165, 0.4451]
Val_Loss: 0.521313, Val_Acc: 0.833333

Epoch #051, Train_Loss: [0.4536, 0.5724, 0.5741, 0.4410, 0.4473]
Val_Loss: 0.521150, Val_Acc: 0.777778

Epoch #052, Train_Loss: [0.5840, 0.5546, 0.3823, 0.4166, 0.5402]
Val_Loss: 0.518023, Val_Acc: 0.833333

Epoch #053, Train_Loss: [0.4333, 0.4917, 0.3803, 0.7072, 0.4049]
Val_Loss: 0.520087, Val_Acc: 0.777778

Epoch #054, Train_Loss: [0.5307, 0.5337, 0.4293, 0.4628, 0.2906]
Val_Loss: 0.536055, Val_Acc: 0.777778

Epoch #055, Train_Loss: [0.5898, 0.4650, 0.3465, 0.4578, 0.5268]
Val_Loss: 0.531775, Val_Acc: 0.777778

Epoch #056, Train_Loss: [0.4977, 0.4154, 0.6006, 0.4031, 0.5040]
Val_Loss: 0.497477, Val_Acc: 0.833333
The current best model is saved in: ******** outputs/MUTAG/model.pth *********

Epoch #057, Train_Loss: [0.5429, 0.3701, 0.6002, 0.4159, 0.4001]
Val_Loss: 0.534137, Val_Acc: 0.777778

Epoch #058, Train_Loss: [0.3861, 0.5617, 0.4645, 0.6638, 0.4061]
Val_Loss: 0.533760, Val_Acc: 0.777778

Epoch #059, Train_Loss: [0.3976, 0.6006, 0.5386, 0.4639, 0.3542]
Val_Loss: 0.530061, Val_Acc: 0.833333

Epoch #060, Train_Loss: [0.3480, 0.4938, 0.5763, 0.4492, 0.4835]
Val_Loss: 0.534921, Val_Acc: 0.722222

Epoch #061, Train_Loss: [0.3576, 0.6444, 0.4509, 0.4495, 0.4728]
Val_Loss: 0.532709, Val_Acc: 0.833333

Epoch #062, Train_Loss: [0.4604, 0.6027, 0.5491, 0.4362, 0.4470]
Val_Loss: 0.540618, Val_Acc: 0.833333

Epoch #063, Train_Loss: [0.4706, 0.3204, 0.5813, 0.4605, 0.7006]
Val_Loss: 0.585426, Val_Acc: 0.722222

Epoch #064, Train_Loss: [0.6392, 0.3701, 0.4903, 0.4747, 0.4011]
Val_Loss: 0.536606, Val_Acc: 0.833333

Epoch #065, Train_Loss: [0.3930, 0.4327, 0.5811, 0.5274, 0.4957]
Val_Loss: 0.547685, Val_Acc: 0.722222

Epoch #066, Train_Loss: [0.3746, 0.4826, 0.6159, 0.5307, 0.3719]
Val_Loss: 0.545254, Val_Acc: 0.722222

Epoch #067, Train_Loss: [0.3262, 0.6029, 0.4879, 0.4498, 0.5359]
Val_Loss: 0.521143, Val_Acc: 0.833333

Epoch #068, Train_Loss: [0.4964, 0.4793, 0.4629, 0.5098, 0.4017]
Val_Loss: 0.559974, Val_Acc: 0.722222

Epoch #069, Train_Loss: [0.4059, 0.6421, 0.4059, 0.3977, 0.4649]
Val_Loss: 0.542206, Val_Acc: 0.722222

Epoch #070, Train_Loss: [0.5236, 0.4076, 0.4691, 0.4708, 0.5095]
Val_Loss: 0.535856, Val_Acc: 0.833333

Epoch #071, Train_Loss: [0.6077, 0.4036, 0.4950, 0.3980, 0.5213]
Val_Loss: 0.556693, Val_Acc: 0.722222

Epoch #072, Train_Loss: [0.5151, 0.3671, 0.3315, 0.5514, 0.6521]
Val_Loss: 0.534642, Val_Acc: 0.722222

Epoch #073, Train_Loss: [0.5044, 0.4329, 0.3973, 0.5144, 0.5715]
Val_Loss: 0.538117, Val_Acc: 0.833333

Epoch #074, Train_Loss: [0.5471, 0.5171, 0.4813, 0.4602, 0.2593]
Val_Loss: 0.569328, Val_Acc: 0.722222

Epoch #075, Train_Loss: [0.4407, 0.4421, 0.5288, 0.5429, 0.4505]
Val_Loss: 0.560693, Val_Acc: 0.722222

Epoch #076, Train_Loss: [0.5284, 0.5279, 0.5181, 0.2492, 0.6211]
Val_Loss: 0.543203, Val_Acc: 0.777778

Epoch #077, Train_Loss: [0.3916, 0.4494, 0.5394, 0.5567, 0.3449]
Val_Loss: 0.535705, Val_Acc: 0.777778

Epoch #078, Train_Loss: [0.4617, 0.4600, 0.4704, 0.4274, 0.4602]
Val_Loss: 0.550064, Val_Acc: 0.722222

Epoch #079, Train_Loss: [0.4276, 0.6159, 0.4749, 0.3130, 0.4925]
Val_Loss: 0.546056, Val_Acc: 0.722222

Epoch #080, Train_Loss: [0.5419, 0.4000, 0.4808, 0.4151, 0.4354]
Val_Loss: 0.534554, Val_Acc: 0.777778

Epoch #081, Train_Loss: [0.4303, 0.5755, 0.4353, 0.5143, 0.3334]
Val_Loss: 0.533740, Val_Acc: 0.722222

Epoch #082, Train_Loss: [0.5281, 0.3789, 0.3908, 0.4574, 0.6924]
Val_Loss: 0.572922, Val_Acc: 0.722222

Epoch #083, Train_Loss: [0.4777, 0.5723, 0.4802, 0.3818, 0.4910]
Val_Loss: 0.542608, Val_Acc: 0.833333

Epoch #084, Train_Loss: [0.4559, 0.3932, 0.5467, 0.3981, 0.5753]
Val_Loss: 0.550259, Val_Acc: 0.722222

Epoch #085, Train_Loss: [0.4068, 0.5010, 0.4506, 0.4861, 0.5560]
Val_Loss: 0.525057, Val_Acc: 0.777778

Epoch #086, Train_Loss: [0.4416, 0.6006, 0.3461, 0.3882, 0.6532]
Val_Loss: 0.541307, Val_Acc: 0.722222

Epoch #087, Train_Loss: [0.4244, 0.5311, 0.3254, 0.5586, 0.5568]
Val_Loss: 0.575380, Val_Acc: 0.722222

Epoch #088, Train_Loss: [0.5163, 0.3568, 0.4809, 0.5845, 0.3898]
Val_Loss: 0.526448, Val_Acc: 0.833333

Epoch #089, Train_Loss: [0.4958, 0.5186, 0.4994, 0.3953, 0.4912]
Val_Loss: 0.543279, Val_Acc: 0.722222

Epoch #090, Train_Loss: [0.4341, 0.4879, 0.4627, 0.4496, 0.4589]
Val_Loss: 0.542389, Val_Acc: 0.722222

Epoch #091, Train_Loss: [0.4340, 0.2997, 0.4991, 0.7062, 0.4112]
Val_Loss: 0.533165, Val_Acc: 0.777778

Epoch #092, Train_Loss: [0.5134, 0.3574, 0.4719, 0.4372, 0.5550]
Val_Loss: 0.537376, Val_Acc: 0.722222

Epoch #093, Train_Loss: [0.4417, 0.4079, 0.5259, 0.5001, 0.4477]
Val_Loss: 0.542508, Val_Acc: 0.722222

Epoch #094, Train_Loss: [0.5081, 0.5186, 0.5941, 0.3473, 0.3644]
Val_Loss: 0.535241, Val_Acc: 0.722222

Epoch #095, Train_Loss: [0.3861, 0.3812, 0.5137, 0.5356, 0.4935]
Val_Loss: 0.569017, Val_Acc: 0.722222

Epoch #096, Train_Loss: [0.3226, 0.4026, 0.5689, 0.5883, 0.4287]
Val_Loss: 0.535241, Val_Acc: 0.777778

Epoch #097, Train_Loss: [0.5356, 0.4822, 0.3231, 0.4700, 0.5001]
Val_Loss: 0.543986, Val_Acc: 0.722222

********** TEST START **********
Reload Best Model
The current best model is saved in: ******** outputs/MUTAG/model.pth *********
TEST :: Test_Acc: 0.700000
